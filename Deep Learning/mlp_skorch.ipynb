{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e47b798-be11-47f4-8439-47303a1ba1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from dataset import get_mnist, separate\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05c40ca-19d3-4616-aac8-071f9da6e79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tqdm.std.tqdm, 'cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_tqdm = True\n",
    "tqdm = tqdm if use_tqdm else lambda x:x\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "tqdm, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a92646-73cd-4a09-945a-01482ea1b889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 313)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = get_mnist(batch_size=32)\n",
    "len(loader[0]), len(loader[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d290e84b-d895-4741-be69-e5df592c60a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 1, 28, 28]), torch.Size([60000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = separate(loader[0])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5925e0c-810b-4398-b38a-6b43c3bd6ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 1, 28, 28]), torch.Size([10000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test = separate(loader[1])\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b2cc15-1a50-45b5-9070-da0a8fb9ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = keras.Sequential([layers.Input((1, 28, 28)),\n",
    "                                       layers.Flatten(),\n",
    "                                       layers.Dense(200, activation=\"relu\"),\n",
    "                                       layers.Dense(150, activation=\"relu\"),\n",
    "                                       layers.Dense(num_classes, activation=\"softmax\")])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b310131-650e-4f17-a317-370dca6775d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "pred_y = model(x_train[0:32])\n",
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6bb0d2-c2ed-4b84-b981-b21b2b24c974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.0919\u001b[0m       \u001b[32m0.5750\u001b[0m        \u001b[35m1.8786\u001b[0m  3.3199\n",
      "      2        \u001b[36m1.6533\u001b[0m       \u001b[32m0.7163\u001b[0m        \u001b[35m1.4272\u001b[0m  3.6940\n",
      "      3        \u001b[36m1.2355\u001b[0m       \u001b[32m0.7828\u001b[0m        \u001b[35m1.0625\u001b[0m  3.5130\n",
      "      4        \u001b[36m0.9428\u001b[0m       \u001b[32m0.8214\u001b[0m        \u001b[35m0.8345\u001b[0m  3.4099\n",
      "      5        \u001b[36m0.7660\u001b[0m       \u001b[32m0.8431\u001b[0m        \u001b[35m0.6972\u001b[0m  3.6432\n",
      "      6        \u001b[36m0.6571\u001b[0m       \u001b[32m0.8562\u001b[0m        \u001b[35m0.6095\u001b[0m  3.4766\n",
      "      7        \u001b[36m0.5855\u001b[0m       \u001b[32m0.8662\u001b[0m        \u001b[35m0.5494\u001b[0m  3.5972\n",
      "      8        \u001b[36m0.5351\u001b[0m       \u001b[32m0.8712\u001b[0m        \u001b[35m0.5059\u001b[0m  3.5042\n",
      "      9        \u001b[36m0.4978\u001b[0m       \u001b[32m0.8762\u001b[0m        \u001b[35m0.4729\u001b[0m  3.6824\n",
      "     10        \u001b[36m0.4691\u001b[0m       \u001b[32m0.8812\u001b[0m        \u001b[35m0.4469\u001b[0m  3.4660\n",
      "     11        \u001b[36m0.4462\u001b[0m       \u001b[32m0.8868\u001b[0m        \u001b[35m0.4260\u001b[0m  3.3649\n",
      "     12        \u001b[36m0.4276\u001b[0m       \u001b[32m0.8898\u001b[0m        \u001b[35m0.4087\u001b[0m  3.5164\n",
      "     13        \u001b[36m0.4121\u001b[0m       \u001b[32m0.8923\u001b[0m        \u001b[35m0.3942\u001b[0m  3.4480\n",
      "     14        \u001b[36m0.3989\u001b[0m       \u001b[32m0.8951\u001b[0m        \u001b[35m0.3818\u001b[0m  3.5472\n",
      "     15        \u001b[36m0.3876\u001b[0m       \u001b[32m0.8978\u001b[0m        \u001b[35m0.3711\u001b[0m  3.6174\n",
      "     16        \u001b[36m0.3777\u001b[0m       \u001b[32m0.8990\u001b[0m        \u001b[35m0.3616\u001b[0m  3.4046\n",
      "     17        \u001b[36m0.3689\u001b[0m       \u001b[32m0.9012\u001b[0m        \u001b[35m0.3532\u001b[0m  3.5845\n",
      "     18        \u001b[36m0.3611\u001b[0m       \u001b[32m0.9029\u001b[0m        \u001b[35m0.3457\u001b[0m  3.5688\n",
      "     19        \u001b[36m0.3540\u001b[0m       \u001b[32m0.9042\u001b[0m        \u001b[35m0.3389\u001b[0m  3.6139\n",
      "     20        \u001b[36m0.3475\u001b[0m       \u001b[32m0.9052\u001b[0m        \u001b[35m0.3326\u001b[0m  3.3723\n",
      "     21        \u001b[36m0.3416\u001b[0m       \u001b[32m0.9062\u001b[0m        \u001b[35m0.3269\u001b[0m  3.4318\n",
      "     22        \u001b[36m0.3361\u001b[0m       \u001b[32m0.9077\u001b[0m        \u001b[35m0.3216\u001b[0m  3.4458\n",
      "     23        \u001b[36m0.3310\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m0.3167\u001b[0m  3.4623\n",
      "     24        \u001b[36m0.3263\u001b[0m       \u001b[32m0.9097\u001b[0m        \u001b[35m0.3121\u001b[0m  3.6560\n",
      "     25        \u001b[36m0.3218\u001b[0m       \u001b[32m0.9110\u001b[0m        \u001b[35m0.3077\u001b[0m  3.7794\n",
      "     26        \u001b[36m0.3176\u001b[0m       \u001b[32m0.9113\u001b[0m        \u001b[35m0.3036\u001b[0m  3.5292\n",
      "     27        \u001b[36m0.3136\u001b[0m       \u001b[32m0.9126\u001b[0m        \u001b[35m0.2998\u001b[0m  3.6771\n",
      "     28        \u001b[36m0.3098\u001b[0m       \u001b[32m0.9131\u001b[0m        \u001b[35m0.2961\u001b[0m  3.4939\n",
      "     29        \u001b[36m0.3061\u001b[0m       \u001b[32m0.9143\u001b[0m        \u001b[35m0.2926\u001b[0m  3.4485\n",
      "     30        \u001b[36m0.3027\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m0.2893\u001b[0m  3.6140\n",
      "     31        \u001b[36m0.2993\u001b[0m       \u001b[32m0.9165\u001b[0m        \u001b[35m0.2861\u001b[0m  3.3755\n",
      "     32        \u001b[36m0.2962\u001b[0m       \u001b[32m0.9176\u001b[0m        \u001b[35m0.2830\u001b[0m  3.5657\n",
      "     33        \u001b[36m0.2931\u001b[0m       \u001b[32m0.9183\u001b[0m        \u001b[35m0.2801\u001b[0m  3.4912\n",
      "     34        \u001b[36m0.2901\u001b[0m       \u001b[32m0.9190\u001b[0m        \u001b[35m0.2772\u001b[0m  3.5081\n",
      "     35        \u001b[36m0.2872\u001b[0m       \u001b[32m0.9197\u001b[0m        \u001b[35m0.2745\u001b[0m  3.5017\n",
      "     36        \u001b[36m0.2844\u001b[0m       \u001b[32m0.9204\u001b[0m        \u001b[35m0.2719\u001b[0m  3.4118\n",
      "     37        \u001b[36m0.2817\u001b[0m       \u001b[32m0.9209\u001b[0m        \u001b[35m0.2693\u001b[0m  3.4212\n",
      "     38        \u001b[36m0.2791\u001b[0m       \u001b[32m0.9220\u001b[0m        \u001b[35m0.2668\u001b[0m  3.4612\n",
      "     39        \u001b[36m0.2766\u001b[0m       \u001b[32m0.9224\u001b[0m        \u001b[35m0.2644\u001b[0m  3.5055\n",
      "     40        \u001b[36m0.2741\u001b[0m       \u001b[32m0.9225\u001b[0m        \u001b[35m0.2621\u001b[0m  3.2341\n",
      "     41        \u001b[36m0.2716\u001b[0m       \u001b[32m0.9237\u001b[0m        \u001b[35m0.2598\u001b[0m  3.4105\n",
      "     42        \u001b[36m0.2693\u001b[0m       \u001b[32m0.9244\u001b[0m        \u001b[35m0.2576\u001b[0m  3.4158\n",
      "     43        \u001b[36m0.2670\u001b[0m       \u001b[32m0.9246\u001b[0m        \u001b[35m0.2554\u001b[0m  3.6091\n",
      "     44        \u001b[36m0.2647\u001b[0m       \u001b[32m0.9253\u001b[0m        \u001b[35m0.2533\u001b[0m  3.5014\n",
      "     45        \u001b[36m0.2625\u001b[0m       \u001b[32m0.9257\u001b[0m        \u001b[35m0.2513\u001b[0m  3.4824\n",
      "     46        \u001b[36m0.2603\u001b[0m       \u001b[32m0.9263\u001b[0m        \u001b[35m0.2493\u001b[0m  3.4326\n",
      "     47        \u001b[36m0.2582\u001b[0m       \u001b[32m0.9268\u001b[0m        \u001b[35m0.2473\u001b[0m  3.6436\n",
      "     48        \u001b[36m0.2561\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m0.2454\u001b[0m  3.4181\n",
      "     49        \u001b[36m0.2541\u001b[0m       \u001b[32m0.9289\u001b[0m        \u001b[35m0.2436\u001b[0m  3.4719\n",
      "     50        \u001b[36m0.2521\u001b[0m       \u001b[32m0.9296\u001b[0m        \u001b[35m0.2417\u001b[0m  3.4246\n",
      "     51        \u001b[36m0.2502\u001b[0m       \u001b[32m0.9298\u001b[0m        \u001b[35m0.2399\u001b[0m  3.5596\n",
      "     52        \u001b[36m0.2482\u001b[0m       \u001b[32m0.9299\u001b[0m        \u001b[35m0.2382\u001b[0m  3.6104\n",
      "     53        \u001b[36m0.2464\u001b[0m       \u001b[32m0.9305\u001b[0m        \u001b[35m0.2365\u001b[0m  3.5176\n",
      "     54        \u001b[36m0.2445\u001b[0m       \u001b[32m0.9312\u001b[0m        \u001b[35m0.2348\u001b[0m  3.5424\n",
      "     55        \u001b[36m0.2427\u001b[0m       \u001b[32m0.9316\u001b[0m        \u001b[35m0.2331\u001b[0m  3.5812\n",
      "     56        \u001b[36m0.2409\u001b[0m       \u001b[32m0.9322\u001b[0m        \u001b[35m0.2315\u001b[0m  3.3777\n",
      "     57        \u001b[36m0.2391\u001b[0m       \u001b[32m0.9326\u001b[0m        \u001b[35m0.2299\u001b[0m  3.5084\n",
      "     58        \u001b[36m0.2374\u001b[0m       \u001b[32m0.9331\u001b[0m        \u001b[35m0.2284\u001b[0m  3.4291\n",
      "     59        \u001b[36m0.2357\u001b[0m       \u001b[32m0.9335\u001b[0m        \u001b[35m0.2268\u001b[0m  3.7021\n",
      "     60        \u001b[36m0.2340\u001b[0m       \u001b[32m0.9340\u001b[0m        \u001b[35m0.2253\u001b[0m  3.5372\n",
      "     61        \u001b[36m0.2323\u001b[0m       \u001b[32m0.9346\u001b[0m        \u001b[35m0.2238\u001b[0m  3.5571\n",
      "     62        \u001b[36m0.2307\u001b[0m       \u001b[32m0.9347\u001b[0m        \u001b[35m0.2224\u001b[0m  3.4610\n",
      "     63        \u001b[36m0.2291\u001b[0m       \u001b[32m0.9353\u001b[0m        \u001b[35m0.2210\u001b[0m  3.4679\n",
      "     64        \u001b[36m0.2275\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m0.2195\u001b[0m  3.4691\n",
      "     65        \u001b[36m0.2259\u001b[0m       \u001b[32m0.9366\u001b[0m        \u001b[35m0.2182\u001b[0m  3.4385\n",
      "     66        \u001b[36m0.2244\u001b[0m       \u001b[32m0.9373\u001b[0m        \u001b[35m0.2168\u001b[0m  3.5872\n",
      "     67        \u001b[36m0.2228\u001b[0m       \u001b[32m0.9376\u001b[0m        \u001b[35m0.2154\u001b[0m  3.5912\n",
      "     68        \u001b[36m0.2213\u001b[0m       \u001b[32m0.9379\u001b[0m        \u001b[35m0.2141\u001b[0m  3.6193\n",
      "     69        \u001b[36m0.2198\u001b[0m       \u001b[32m0.9385\u001b[0m        \u001b[35m0.2128\u001b[0m  3.4757\n",
      "     70        \u001b[36m0.2183\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.2115\u001b[0m  3.6568\n",
      "     71        \u001b[36m0.2169\u001b[0m       \u001b[32m0.9392\u001b[0m        \u001b[35m0.2102\u001b[0m  3.3460\n",
      "     72        \u001b[36m0.2155\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m0.2090\u001b[0m  3.5265\n",
      "     73        \u001b[36m0.2140\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m0.2077\u001b[0m  3.5410\n",
      "     74        \u001b[36m0.2126\u001b[0m       \u001b[32m0.9403\u001b[0m        \u001b[35m0.2065\u001b[0m  3.6774\n",
      "     75        \u001b[36m0.2112\u001b[0m       \u001b[32m0.9404\u001b[0m        \u001b[35m0.2053\u001b[0m  3.3895\n",
      "     76        \u001b[36m0.2099\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m0.2041\u001b[0m  3.4277\n",
      "     77        \u001b[36m0.2085\u001b[0m       0.9407        \u001b[35m0.2029\u001b[0m  3.5797\n",
      "     78        \u001b[36m0.2072\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m0.2017\u001b[0m  3.2613\n",
      "     79        \u001b[36m0.2059\u001b[0m       \u001b[32m0.9415\u001b[0m        \u001b[35m0.2006\u001b[0m  3.4659\n",
      "     80        \u001b[36m0.2046\u001b[0m       \u001b[32m0.9420\u001b[0m        \u001b[35m0.1995\u001b[0m  3.4222\n",
      "     81        \u001b[36m0.2033\u001b[0m       \u001b[32m0.9423\u001b[0m        \u001b[35m0.1983\u001b[0m  3.5021\n",
      "     82        \u001b[36m0.2020\u001b[0m       \u001b[32m0.9427\u001b[0m        \u001b[35m0.1972\u001b[0m  3.7127\n",
      "     83        \u001b[36m0.2007\u001b[0m       0.9427        \u001b[35m0.1961\u001b[0m  3.5971\n",
      "     84        \u001b[36m0.1995\u001b[0m       \u001b[32m0.9430\u001b[0m        \u001b[35m0.1951\u001b[0m  3.4662\n",
      "     85        \u001b[36m0.1983\u001b[0m       \u001b[32m0.9433\u001b[0m        \u001b[35m0.1940\u001b[0m  3.6027\n",
      "     86        \u001b[36m0.1971\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m0.1930\u001b[0m  3.6179\n",
      "     87        \u001b[36m0.1959\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m0.1919\u001b[0m  3.4634\n",
      "     88        \u001b[36m0.1947\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m0.1909\u001b[0m  3.5069\n",
      "     89        \u001b[36m0.1935\u001b[0m       \u001b[32m0.9443\u001b[0m        \u001b[35m0.1899\u001b[0m  3.5140\n",
      "     90        \u001b[36m0.1923\u001b[0m       \u001b[32m0.9445\u001b[0m        \u001b[35m0.1889\u001b[0m  3.6107\n",
      "     91        \u001b[36m0.1912\u001b[0m       \u001b[32m0.9449\u001b[0m        \u001b[35m0.1879\u001b[0m  3.4845\n",
      "     92        \u001b[36m0.1901\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m0.1870\u001b[0m  3.6103\n",
      "     93        \u001b[36m0.1889\u001b[0m       \u001b[32m0.9453\u001b[0m        \u001b[35m0.1860\u001b[0m  3.4593\n",
      "     94        \u001b[36m0.1878\u001b[0m       \u001b[32m0.9456\u001b[0m        \u001b[35m0.1851\u001b[0m  3.5228\n",
      "     95        \u001b[36m0.1867\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m0.1841\u001b[0m  3.3588\n",
      "     96        \u001b[36m0.1857\u001b[0m       \u001b[32m0.9459\u001b[0m        \u001b[35m0.1832\u001b[0m  3.4685\n",
      "     97        \u001b[36m0.1846\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m0.1823\u001b[0m  3.6900\n",
      "     98        \u001b[36m0.1835\u001b[0m       \u001b[32m0.9463\u001b[0m        \u001b[35m0.1814\u001b[0m  3.4590\n",
      "     99        \u001b[36m0.1825\u001b[0m       \u001b[32m0.9465\u001b[0m        \u001b[35m0.1805\u001b[0m  3.5894\n",
      "    100        \u001b[36m0.1814\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.1797\u001b[0m  3.5440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Model(\n",
       "    (model): <Sequential name=sequential_1, built=True>\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default loss: NLLL\n",
    "net = NeuralNetClassifier(Model, max_epochs=100, lr=1e-3, \n",
    "                          batch_size=64, device=device)\n",
    "net.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6bfb61-4440-4b29-acbf-a9c137f10a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net.predict(x_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b84b4d17-81ef-460b-b190-490d5dff35c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.87253089e-04, 6.51116494e-08, 1.57244783e-03, 4.62581497e-03,\n",
       "        6.26708186e-07, 6.75435076e-05, 2.90309843e-09, 9.93242919e-01,\n",
       "        2.36440646e-05, 1.79695126e-04],\n",
       "       [1.35735760e-03, 5.47884338e-05, 9.90217090e-01, 4.85721650e-03,\n",
       "        3.35569728e-09, 6.44412881e-04, 1.32739602e-03, 1.96229237e-08,\n",
       "        1.54179730e-03, 1.53010440e-08],\n",
       "       [3.84867781e-05, 9.82056081e-01, 5.07624680e-03, 2.78334250e-03,\n",
       "        3.74092691e-04, 2.20517907e-03, 1.65344658e-03, 3.23489471e-03,\n",
       "        2.16250122e-03, 4.15793387e-04],\n",
       "       [9.99661446e-01, 6.19082785e-09, 1.19113945e-04, 1.27402373e-05,\n",
       "        5.72676200e-08, 1.24894039e-04, 5.69772419e-05, 1.35747741e-05,\n",
       "        3.50653022e-06, 7.71041323e-06],\n",
       "       [2.77731975e-04, 1.30999451e-05, 1.42478058e-03, 1.21169527e-04,\n",
       "        9.60752070e-01, 3.41278152e-04, 1.32051320e-03, 3.66160204e-03,\n",
       "        3.69204528e-04, 3.17184590e-02]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = net.predict_proba(x_test[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ca391b-fc04-4ed1-b50f-9b212f358833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9e242b1-f0af-4dbe-b90d-e21fc1444f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = keras.Sequential([layers.Input((1, 28, 28)),\n",
    "                                       layers.Flatten(),\n",
    "                                       layers.Dense(200, activation=\"relu\"),\n",
    "                                       layers.Dense(150, activation=\"relu\"),\n",
    "                                       layers.Dense(num_classes)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abf8b533-987c-45b3-8a94-dd9d8b004f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.1237\u001b[0m       \u001b[32m0.5627\u001b[0m        \u001b[35m1.9309\u001b[0m  3.2788\n",
      "      2        \u001b[36m1.7116\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m1.4785\u001b[0m  3.3370\n",
      "      3        \u001b[36m1.2727\u001b[0m       \u001b[32m0.8014\u001b[0m        \u001b[35m1.0796\u001b[0m  3.4517\n",
      "      4        \u001b[36m0.9504\u001b[0m       \u001b[32m0.8328\u001b[0m        \u001b[35m0.8299\u001b[0m  3.3002\n",
      "      5        \u001b[36m0.7599\u001b[0m       \u001b[32m0.8489\u001b[0m        \u001b[35m0.6855\u001b[0m  3.2967\n",
      "      6        \u001b[36m0.6475\u001b[0m       \u001b[32m0.8609\u001b[0m        \u001b[35m0.5969\u001b[0m  3.4231\n",
      "      7        \u001b[36m0.5759\u001b[0m       \u001b[32m0.8672\u001b[0m        \u001b[35m0.5380\u001b[0m  3.5635\n",
      "      8        \u001b[36m0.5268\u001b[0m       \u001b[32m0.8721\u001b[0m        \u001b[35m0.4962\u001b[0m  3.4567\n",
      "      9        \u001b[36m0.4910\u001b[0m       \u001b[32m0.8772\u001b[0m        \u001b[35m0.4649\u001b[0m  3.4366\n",
      "     10        \u001b[36m0.4637\u001b[0m       \u001b[32m0.8822\u001b[0m        \u001b[35m0.4404\u001b[0m  3.3310\n",
      "     11        \u001b[36m0.4420\u001b[0m       \u001b[32m0.8848\u001b[0m        \u001b[35m0.4207\u001b[0m  3.3043\n",
      "     12        \u001b[36m0.4244\u001b[0m       \u001b[32m0.8875\u001b[0m        \u001b[35m0.4043\u001b[0m  3.3430\n",
      "     13        \u001b[36m0.4096\u001b[0m       \u001b[32m0.8908\u001b[0m        \u001b[35m0.3906\u001b[0m  3.4209\n",
      "     14        \u001b[36m0.3970\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.3787\u001b[0m  3.5442\n",
      "     15        \u001b[36m0.3861\u001b[0m       \u001b[32m0.8963\u001b[0m        \u001b[35m0.3683\u001b[0m  3.6298\n",
      "     16        \u001b[36m0.3764\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.3591\u001b[0m  3.5475\n",
      "     17        \u001b[36m0.3679\u001b[0m       \u001b[32m0.8988\u001b[0m        \u001b[35m0.3509\u001b[0m  3.6007\n",
      "     18        \u001b[36m0.3601\u001b[0m       \u001b[32m0.9002\u001b[0m        \u001b[35m0.3435\u001b[0m  3.3344\n",
      "     19        \u001b[36m0.3531\u001b[0m       \u001b[32m0.9017\u001b[0m        \u001b[35m0.3368\u001b[0m  3.2872\n",
      "     20        \u001b[36m0.3467\u001b[0m       \u001b[32m0.9037\u001b[0m        \u001b[35m0.3306\u001b[0m  3.2051\n",
      "     21        \u001b[36m0.3408\u001b[0m       \u001b[32m0.9052\u001b[0m        \u001b[35m0.3249\u001b[0m  3.3619\n",
      "     22        \u001b[36m0.3353\u001b[0m       \u001b[32m0.9072\u001b[0m        \u001b[35m0.3196\u001b[0m  3.1871\n",
      "     23        \u001b[36m0.3302\u001b[0m       \u001b[32m0.9082\u001b[0m        \u001b[35m0.3146\u001b[0m  3.4971\n",
      "     24        \u001b[36m0.3254\u001b[0m       \u001b[32m0.9095\u001b[0m        \u001b[35m0.3100\u001b[0m  3.2987\n",
      "     25        \u001b[36m0.3209\u001b[0m       \u001b[32m0.9106\u001b[0m        \u001b[35m0.3057\u001b[0m  3.3901\n",
      "     26        \u001b[36m0.3167\u001b[0m       \u001b[32m0.9120\u001b[0m        \u001b[35m0.3016\u001b[0m  3.2749\n",
      "     27        \u001b[36m0.3126\u001b[0m       \u001b[32m0.9130\u001b[0m        \u001b[35m0.2977\u001b[0m  3.2833\n",
      "     28        \u001b[36m0.3088\u001b[0m       \u001b[32m0.9143\u001b[0m        \u001b[35m0.2940\u001b[0m  3.3046\n",
      "     29        \u001b[36m0.3051\u001b[0m       \u001b[32m0.9153\u001b[0m        \u001b[35m0.2905\u001b[0m  3.3763\n",
      "     30        \u001b[36m0.3016\u001b[0m       \u001b[32m0.9163\u001b[0m        \u001b[35m0.2872\u001b[0m  3.3582\n",
      "     31        \u001b[36m0.2983\u001b[0m       \u001b[32m0.9174\u001b[0m        \u001b[35m0.2840\u001b[0m  3.2112\n",
      "     32        \u001b[36m0.2951\u001b[0m       \u001b[32m0.9183\u001b[0m        \u001b[35m0.2809\u001b[0m  3.2428\n",
      "     33        \u001b[36m0.2920\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.2780\u001b[0m  3.3373\n",
      "     34        \u001b[36m0.2890\u001b[0m       \u001b[32m0.9201\u001b[0m        \u001b[35m0.2751\u001b[0m  3.4374\n",
      "     35        \u001b[36m0.2861\u001b[0m       \u001b[32m0.9209\u001b[0m        \u001b[35m0.2724\u001b[0m  3.2524\n",
      "     36        \u001b[36m0.2833\u001b[0m       \u001b[32m0.9213\u001b[0m        \u001b[35m0.2698\u001b[0m  3.3493\n",
      "     37        \u001b[36m0.2806\u001b[0m       \u001b[32m0.9217\u001b[0m        \u001b[35m0.2672\u001b[0m  3.2575\n",
      "     38        \u001b[36m0.2780\u001b[0m       \u001b[32m0.9227\u001b[0m        \u001b[35m0.2647\u001b[0m  3.3848\n",
      "     39        \u001b[36m0.2754\u001b[0m       \u001b[32m0.9233\u001b[0m        \u001b[35m0.2623\u001b[0m  3.3855\n",
      "     40        \u001b[36m0.2729\u001b[0m       \u001b[32m0.9237\u001b[0m        \u001b[35m0.2600\u001b[0m  3.4367\n",
      "     41        \u001b[36m0.2705\u001b[0m       \u001b[32m0.9242\u001b[0m        \u001b[35m0.2577\u001b[0m  3.2826\n",
      "     42        \u001b[36m0.2682\u001b[0m       \u001b[32m0.9251\u001b[0m        \u001b[35m0.2555\u001b[0m  3.2268\n",
      "     43        \u001b[36m0.2659\u001b[0m       \u001b[32m0.9256\u001b[0m        \u001b[35m0.2534\u001b[0m  3.4818\n",
      "     44        \u001b[36m0.2637\u001b[0m       \u001b[32m0.9263\u001b[0m        \u001b[35m0.2513\u001b[0m  3.4240\n",
      "     45        \u001b[36m0.2615\u001b[0m       \u001b[32m0.9272\u001b[0m        \u001b[35m0.2492\u001b[0m  3.3571\n",
      "     46        \u001b[36m0.2593\u001b[0m       \u001b[32m0.9279\u001b[0m        \u001b[35m0.2473\u001b[0m  3.2659\n",
      "     47        \u001b[36m0.2572\u001b[0m       \u001b[32m0.9282\u001b[0m        \u001b[35m0.2453\u001b[0m  3.2986\n",
      "     48        \u001b[36m0.2552\u001b[0m       \u001b[32m0.9289\u001b[0m        \u001b[35m0.2434\u001b[0m  3.2964\n",
      "     49        \u001b[36m0.2532\u001b[0m       \u001b[32m0.9294\u001b[0m        \u001b[35m0.2416\u001b[0m  3.4344\n",
      "     50        \u001b[36m0.2512\u001b[0m       \u001b[32m0.9299\u001b[0m        \u001b[35m0.2398\u001b[0m  3.2830\n",
      "     51        \u001b[36m0.2493\u001b[0m       \u001b[32m0.9306\u001b[0m        \u001b[35m0.2380\u001b[0m  3.4265\n",
      "     52        \u001b[36m0.2474\u001b[0m       \u001b[32m0.9313\u001b[0m        \u001b[35m0.2363\u001b[0m  3.4300\n",
      "     53        \u001b[36m0.2455\u001b[0m       \u001b[32m0.9316\u001b[0m        \u001b[35m0.2346\u001b[0m  3.2914\n",
      "     54        \u001b[36m0.2437\u001b[0m       \u001b[32m0.9319\u001b[0m        \u001b[35m0.2329\u001b[0m  3.3558\n",
      "     55        \u001b[36m0.2419\u001b[0m       \u001b[32m0.9324\u001b[0m        \u001b[35m0.2313\u001b[0m  3.2575\n",
      "     56        \u001b[36m0.2402\u001b[0m       \u001b[32m0.9327\u001b[0m        \u001b[35m0.2297\u001b[0m  3.4512\n",
      "     57        \u001b[36m0.2384\u001b[0m       \u001b[32m0.9329\u001b[0m        \u001b[35m0.2281\u001b[0m  3.3412\n",
      "     58        \u001b[36m0.2367\u001b[0m       \u001b[32m0.9334\u001b[0m        \u001b[35m0.2266\u001b[0m  3.3003\n",
      "     59        \u001b[36m0.2350\u001b[0m       \u001b[32m0.9342\u001b[0m        \u001b[35m0.2250\u001b[0m  3.3108\n",
      "     60        \u001b[36m0.2334\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m0.2235\u001b[0m  3.4210\n",
      "     61        \u001b[36m0.2318\u001b[0m       \u001b[32m0.9349\u001b[0m        \u001b[35m0.2221\u001b[0m  3.2872\n",
      "     62        \u001b[36m0.2302\u001b[0m       \u001b[32m0.9355\u001b[0m        \u001b[35m0.2206\u001b[0m  3.4067\n",
      "     63        \u001b[36m0.2286\u001b[0m       \u001b[32m0.9363\u001b[0m        \u001b[35m0.2192\u001b[0m  3.3751\n",
      "     64        \u001b[36m0.2271\u001b[0m       \u001b[32m0.9367\u001b[0m        \u001b[35m0.2178\u001b[0m  3.4262\n",
      "     65        \u001b[36m0.2255\u001b[0m       \u001b[32m0.9370\u001b[0m        \u001b[35m0.2164\u001b[0m  3.4378\n",
      "     66        \u001b[36m0.2240\u001b[0m       \u001b[32m0.9374\u001b[0m        \u001b[35m0.2151\u001b[0m  3.3285\n",
      "     67        \u001b[36m0.2225\u001b[0m       \u001b[32m0.9379\u001b[0m        \u001b[35m0.2137\u001b[0m  3.4070\n",
      "     68        \u001b[36m0.2211\u001b[0m       \u001b[32m0.9388\u001b[0m        \u001b[35m0.2124\u001b[0m  3.3326\n",
      "     69        \u001b[36m0.2196\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m0.2111\u001b[0m  3.3029\n",
      "     70        \u001b[36m0.2182\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m0.2098\u001b[0m  3.3145\n",
      "     71        \u001b[36m0.2167\u001b[0m       \u001b[32m0.9400\u001b[0m        \u001b[35m0.2086\u001b[0m  3.3424\n",
      "     72        \u001b[36m0.2153\u001b[0m       \u001b[32m0.9406\u001b[0m        \u001b[35m0.2073\u001b[0m  3.3775\n",
      "     73        \u001b[36m0.2140\u001b[0m       \u001b[32m0.9407\u001b[0m        \u001b[35m0.2061\u001b[0m  3.3587\n",
      "     74        \u001b[36m0.2126\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m0.2049\u001b[0m  3.4050\n",
      "     75        \u001b[36m0.2112\u001b[0m       \u001b[32m0.9413\u001b[0m        \u001b[35m0.2037\u001b[0m  3.5482\n",
      "     76        \u001b[36m0.2099\u001b[0m       0.9413        \u001b[35m0.2026\u001b[0m  3.2435\n",
      "     77        \u001b[36m0.2086\u001b[0m       0.9413        \u001b[35m0.2014\u001b[0m  3.3521\n",
      "     78        \u001b[36m0.2073\u001b[0m       \u001b[32m0.9419\u001b[0m        \u001b[35m0.2002\u001b[0m  3.4737\n",
      "     79        \u001b[36m0.2060\u001b[0m       \u001b[32m0.9421\u001b[0m        \u001b[35m0.1991\u001b[0m  3.2545\n",
      "     80        \u001b[36m0.2047\u001b[0m       \u001b[32m0.9423\u001b[0m        \u001b[35m0.1980\u001b[0m  3.2531\n",
      "     81        \u001b[36m0.2035\u001b[0m       \u001b[32m0.9428\u001b[0m        \u001b[35m0.1969\u001b[0m  3.4480\n",
      "     82        \u001b[36m0.2022\u001b[0m       \u001b[32m0.9433\u001b[0m        \u001b[35m0.1958\u001b[0m  3.3354\n",
      "     83        \u001b[36m0.2010\u001b[0m       \u001b[32m0.9436\u001b[0m        \u001b[35m0.1947\u001b[0m  3.5112\n",
      "     84        \u001b[36m0.1998\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m0.1937\u001b[0m  3.3629\n",
      "     85        \u001b[36m0.1986\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m0.1926\u001b[0m  3.5457\n",
      "     86        \u001b[36m0.1974\u001b[0m       \u001b[32m0.9441\u001b[0m        \u001b[35m0.1916\u001b[0m  3.5295\n",
      "     87        \u001b[36m0.1962\u001b[0m       \u001b[32m0.9443\u001b[0m        \u001b[35m0.1906\u001b[0m  3.3002\n",
      "     88        \u001b[36m0.1951\u001b[0m       \u001b[32m0.9445\u001b[0m        \u001b[35m0.1896\u001b[0m  3.1972\n",
      "     89        \u001b[36m0.1939\u001b[0m       \u001b[32m0.9450\u001b[0m        \u001b[35m0.1886\u001b[0m  3.3956\n",
      "     90        \u001b[36m0.1928\u001b[0m       0.9450        \u001b[35m0.1876\u001b[0m  3.4572\n",
      "     91        \u001b[36m0.1917\u001b[0m       0.9450        \u001b[35m0.1867\u001b[0m  3.3687\n",
      "     92        \u001b[36m0.1906\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m0.1857\u001b[0m  3.4334\n",
      "     93        \u001b[36m0.1895\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m0.1848\u001b[0m  3.3054\n",
      "     94        \u001b[36m0.1884\u001b[0m       \u001b[32m0.9460\u001b[0m        \u001b[35m0.1839\u001b[0m  3.3409\n",
      "     95        \u001b[36m0.1873\u001b[0m       \u001b[32m0.9464\u001b[0m        \u001b[35m0.1829\u001b[0m  3.4368\n",
      "     96        \u001b[36m0.1862\u001b[0m       \u001b[32m0.9466\u001b[0m        \u001b[35m0.1820\u001b[0m  3.4191\n",
      "     97        \u001b[36m0.1852\u001b[0m       \u001b[32m0.9468\u001b[0m        \u001b[35m0.1812\u001b[0m  3.2859\n",
      "     98        \u001b[36m0.1842\u001b[0m       \u001b[32m0.9471\u001b[0m        \u001b[35m0.1803\u001b[0m  3.5374\n",
      "     99        \u001b[36m0.1831\u001b[0m       0.9471        \u001b[35m0.1794\u001b[0m  3.3737\n",
      "    100        \u001b[36m0.1821\u001b[0m       0.9470        \u001b[35m0.1785\u001b[0m  3.3824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Model(\n",
       "    (model): <Sequential name=sequential_2, built=True>\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(Model, max_epochs=100, lr=1e-3, \n",
    "                          criterion=nn.CrossEntropyLoss, \n",
    "                          batch_size=64, device=device)\n",
    "net.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba8ade1-92ec-4ab7-9e4f-1d313138df81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net.predict(x_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0186da65-a1bb-4be5-80ab-b2a5362992a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5121060e-05, 4.4103300e-07, 1.3751260e-03, 5.6029479e-03,\n",
       "        5.3078026e-07, 4.0260660e-05, 4.9278217e-09, 9.9266428e-01,\n",
       "        9.0585327e-06, 2.1225419e-04],\n",
       "       [9.0250460e-04, 3.3562185e-04, 9.7455263e-01, 8.6080274e-03,\n",
       "        1.2145846e-07, 4.4421223e-03, 9.0637570e-03, 5.2779727e-09,\n",
       "        2.0951836e-03, 3.6420548e-08],\n",
       "       [2.3558026e-05, 9.8523468e-01, 5.1164851e-03, 1.6299746e-03,\n",
       "        4.2730672e-04, 2.6301788e-03, 1.5003354e-03, 2.0845814e-03,\n",
       "        1.1033247e-03, 2.4967152e-04],\n",
       "       [9.9943763e-01, 2.2198115e-08, 3.8761937e-04, 1.7450084e-05,\n",
       "        9.0123763e-08, 8.1105056e-05, 2.9317882e-05, 3.1880671e-05,\n",
       "        2.2580439e-06, 1.2557837e-05],\n",
       "       [5.3675211e-04, 1.1447048e-05, 4.0593916e-03, 1.7273609e-04,\n",
       "        9.5664155e-01, 4.5337901e-04, 5.6341873e-03, 3.3983132e-03,\n",
       "        1.7718109e-03, 2.7320391e-02]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = net.predict_proba(x_test[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2a0980-7459-405d-88a2-a161fbb0a719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
