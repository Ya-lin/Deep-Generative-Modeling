from types import SimpleNamespace
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from tqdm import tqdm

import torch
from torch import nn, optim
import keras
from keras import layers, models
from dataset import get_data
from network import VAE
from training import trainer
from testing import reconstruction, display





args = SimpleNamespace(dataset="fmnist")
args.device ="cuda" if torch.cuda.is_available() else "cpu"
args.img = 32       # image size
args.ch = 1         # num of channel
args.batch = 100    # batch size
args.dim = 2        # embedding dimension
args.epoch = 20
args.lr = 5e-4
args.gamma = 500        # weight for reconstruction loss (use bce loss)
print(args)





loader = get_data(args.dataset, args.batch)
print(f"\n{len(loader.train) = }")
print(f"\n{len(loader.test) = }")


x, y = next(iter(loader.train))
print(f"\n{x.shape = }")
print(f"\n{y.shape = }")


model = VAE(args.img, args.ch, args.dim, args.gamma, args.device)
print("\n", model.shape_bf)
print("\n", model.encoder.summary())
print("\n", model.decoder.summary())





model = VAE(args.img, args.ch, args.dim, args.gamma, args.device)
optimizer = optim.Adam(model.parameters(), lr=args.lr)
model, history = trainer(model, loader, args.epoch, optimizer)
model.training


plt.plot(history.train, label="train loss")
plt.plot(history.test, label="test loss")
plt.legend()
plt.show()


# load the saved model
checkpoint = torch.load("best_model.pth", weights_only=True)
model.load_state_dict(checkpoint["model_dict"])
model.training





x, _ = next(iter(loader.test))
with torch.no_grad():
    x_hat, *_, z = model(x)
    x_hat = x_hat.cpu()
    z = z.cpu()


print("Example real clothing items")
display(x)
print("Reconstructions")
display(x_hat)





grid_width, grid_height = (6, 3)
g_sample, z_sample = model.sampling(grid_width*grid_height, latent_sample=True)
g_sample = g_sample.squeeze().numpy()
z_sample = z_sample.numpy()
en_z = z.numpy()
print(en_z.shape, z_sample.shape, g_sample.shape)


figsize = 8
fig = plt.figure(figsize=(2 * figsize, figsize))
gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])

# original embedding and generated sample in the latent space
ax1 = plt.subplot(gs[0])
ax1.scatter(en_z[:, 0], en_z[:, 1], c="black", alpha=0.5, s=2)
ax1.scatter(z_sample[:, 0], z_sample[:, 1], c="#00B0F0", alpha=1, s=40)
ax1.set_title('Original and Sampled Points')

gs2 = gridspec.GridSpecFromSubplotSpec(grid_height, grid_width, subplot_spec=gs[1], hspace=0.4, wspace=0.4)
for i in range(grid_width * grid_height):
    ax = plt.subplot(gs2[i])
    ax.axis("off")
    ax.text(0.5, -0.35, str(np.round(z_sample[i % len(z_sample),:], 1)), 
            fontsize=10, ha="center", transform=ax.transAxes)
    ax.imshow(g_sample[i, :, :].squeeze(), cmap="Greys")

plt.tight_layout()
plt.show()



