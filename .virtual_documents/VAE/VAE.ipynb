from types import SimpleNamespace
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

import torch
from torch import nn, optim
from torch.nn import functional as F

import keras
from keras import layers, models
from dataset import get_data
from network import get_encoder, get_decoder, VAE
from training import trainer
from testing import reconstruction, display


args = SimpleNamespace(dataset="fmnist")
args.device ="cuda" if torch.cuda.is_available() else "cpu"
args.img = 32       # image size
args.ch = 1         # num of channel
args.batch = 100    # batch size
args.dim = 2        # embedding dimension
args.epoch = 10
args.lr = 1e-3
args.gamma = 500        # weight for reconstruction loss (use bce loss)
print(args)


loader = get_data(args.dataset, args.batch)
len(loader.train), len(loader.test)


x, y = next(iter(loader.train))
x.shape, y.shape


model = VAE(args.img, args.ch, args.dim, args.gamma, args.device)
print("\n", model.shape_bf)
print("\n", model.encoder.summary())
print("\n", model.decoder.summary())


model = VAE(args.img, args.ch, args.dim, args.gamma, args.device)
optimizer = optim.Adam(model.parameters(), lr=args.lr)
model, history = trainer(model, loader, args.epoch, optimizer)
model.training


plt.plot(history.train, label="train loss")
plt.plot(history.test, label="test loss")
plt.legend()
plt.show()


# load the saved model
checkpoint = torch.load("best_model.pth", weights_only=True)
model.load_state_dict(checkpoint["model_dict"])
model.training



